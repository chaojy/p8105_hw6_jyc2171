---
title: "Homework 6"
author: "Jerry Chao, UNI: jyc 2171"
output: github_document
---

```{r setup, echo = FALSE}
library(tidyverse)
library(modelr)
library(p8105.datasets)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

### Problem 1

```{r}
homicide_df =
  read_csv("./data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>%
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL"
  )  %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with one city.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex,
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

Try this across cities - not just Baltimore, but for every city in my dataset.
The process for this is:
(1) Nesting my dataset - so that I get a dataframe for each city
(2) Map over that list, fitting the regression model that I care about for each city
(3) Tidy up the results by mapping across regression models
(4) At the end of that, I am left with another dataframe with contains city, estimates of odds ratios and intercept, and look at these effects city-by-city

```{r}
models_results_df =
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))

#check to make sure the model matches baltimore_df from above as an intermediate check
#models_results_df %>% 
#  filter(city_state == "Baltimore, MD") %>% 
#  pull(models) 
```

Make a plot - similar to last homework - of ORs, comparing male to female across cities.  Across cities, are males vs. females more or less likely to have their homoicides resolved?

```{r}
models_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(
    city_state = fct_reorder(city_state, OR)
  ) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
#Interpretation: male sex is associated with lower likelihood of having homicides resolved compared to females
```

# Problem 2

```{r, echo = FALSE}
#This code chunk includes my notes from synchronous class as guidance, please ignore.  Thanks.

# Fit two models as specified, third model is our discretion (deliberately open ended)
# then compare the three models using cross validation
# 
# Process:
# (1) Fit the two specified models
# (2) Do cross-validation on those based on the lecture videos - get cross-validation to work on this new dataset
# Then,
# (3) Spend some time building your model = fit some models, look for statistical significant, look at residuals, etc.  Your model should be better than the first model, maybe better than the 3-way interaction model

# evaluating residuals:
# (1) Is there skewness in the distribution?
# (2) Is there any sort of trend?  Linear?  Non-linear?  Parabola?

# Find some residuals
# 
# baby_df =
#   read_csv("./data/birthweight.csv")
# 
# fit a model
# model_fit = lm(bwt ~ gaweeks, data = baby_df)
# 
# baby_df %>% 
#   modelr::add_residuals(model_fit) %>% 
#   ggplot(aes(x = resid)) +
#   geom_density()
# 
# baby_df %>% 
#   modelr::add_residuals(model_fit) %>% 
#   ggplot(aes(x = gaweeks, y = resid)) +
#   geom_point()
```

This is my solution for Problem 2

My solution to Problem 2 is structured in 4 parts:
(1) Import, clean, and tidying the data.
(2) Explore the data and fit my model, explaining my rationale and model-building process, followed by diagnostics using add_residuals and add_predictions.
(3) Perform cross-validation of the 2 specified models in the homework stem, as a start, in order to make sure I can do it.
(4) Perform cross-validation including all 3 models.

First, I have assigned an id number to each observation.  Next, I have assigned the corresponding variable names to their numerical coding. I have converted some units so that they make more sense to me: birth weight from grams to kilograms, all weights in pounds to kilograms, and family monthly income from hundreds to single units (e.g., 35 to 3500).  I have deselected "pnumlbw" and "pnumsga", since all observations for these variables are zero.  I have converted "babysex" to a factor variable, since it may be interesting to look at variables by biological sex, and I have releveled such that female is the reference category.  I have also releveled mrace with white as the reference level.  There does not appear to be much missing data.
```{r, import, clean, and tidy}
baby_df =
  read_csv("./data/birthweight.csv") %>% 
  mutate(
    id = sample(1:4342, 4342),
    babysex = recode(babysex, "2" = "female", "1" = "male"),
    babysex = fct_relevel(babysex, "female", "male"),
    bwt = bwt / 1000,
    momwt = delwt / 2.2046226218,
    fincome = fincome * 100,
    frace = 
      recode(frace, "1" = "white", "2" = "black", "3" = "asian", "4" = "puerto rican", "8" = "other", "9" = "unknown"),
    frace = fct_relevel(frace, "white", "black", "puerto rican", "asian", "other"),
    malform = recode(malform, "0" = "absent", "1" = "present"),
    mheight = mheight * 2.54,
    mrace = recode(mrace, "1" = "white", "2" = "black", "3" = "asian", "4" = "puerto rican", "8" = "other"),
    mrace = fct_relevel(mrace, "white", "black", "puerto rican", "asian"),
    ppwt = ppwt / 2.2046226218,
    wtgain = wtgain / 2.2046226218
  ) %>% 
  select(id, babysex, bhead, blength, bwt, momwt, everything(), -delwt, -pnumlbw, -pnumsga) %>% 
  arrange(id)
```

Some univariate exploratory plots to check my data cleaning AND explore some general associations.
```{r, eval = FALSE}
baby_df %>% 
  ggplot(aes(x = babysex, y = bwt)) +
  geom_boxplot()

baby_df %>% 
  ggplot(aes(x = bwt, group = babysex, fill = babysex)) +
  geom_density(alpha = .5)

baby_df %>% 
  mutate(
    mrace = as.factor(mrace),
    mrace = fct_reorder(mrace, bwt)
  ) %>% 
  ggplot(aes(x = mrace, y = bwt)) +
  geom_boxplot()
#maternal race seems associated

baby_df %>% 
  mutate(
    frace = as.factor(frace),
    frace = fct_reorder(frace, bwt)
  ) %>% 
  ggplot(aes(x = frace, y = bwt)) +
  geom_boxplot()

baby_df %>% 
  ggplot(aes(x = momwt, y = bwt)) +
  geom_point()

baby_df %>% 
  ggplot(aes(x = ppwt, y = bwt)) +
  geom_point()

baby_df %>% 
  ggplot(aes(x = bhead, y = bwt)) +
  geom_point()
  
baby_df %>% 
  mutate(
    bhead = as.factor(bhead),
    bhead = fct_reorder(bhead, bwt)
  ) %>% 
  ggplot(aes(x = bhead, y = bwt)) +
  geom_boxplot()
#bhead seems strongly associated with bwt

baby_df %>% 
  ggplot(aes(x = blength, y = bwt)) +
  geom_point()

baby_df %>% 
  mutate(
    blength = as.factor(blength),
    blength = fct_reorder(blength, bwt)
  ) %>% 
  ggplot(aes(x = blength, y = bwt)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

baby_df %>% 
  ggplot(aes(x = gaweeks, y = bwt)) +
  geom_point()

baby_df %>% 
  mutate(
    gaweeks = as.factor(gaweeks),
    gaweeks = fct_reorder(gaweeks, bwt)
  ) %>% 
  ggplot(aes(x = gaweeks, y = bwt)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

baby_df %>% 
  ggplot(aes(x = fincome, y = bwt)) +
  geom_point()

baby_df %>% 
  mutate(
    fincome = as.factor(fincome),
    fincome = fct_reorder(fincome, bwt)
  ) %>% 
  ggplot(aes(x = fincome, y = bwt)) +
  geom_boxplot()

baby_df %>% 
  ggplot(aes(x = malform, y = bwt)) +
  geom_boxplot()

baby_df %>% 
  ggplot(aes(x = menarche, y = bwt)) +
  geom_point()

baby_df %>% 
  mutate(
    menarche = as.factor(menarche),
    menarche = fct_reorder(menarche, bwt)
  ) %>% 
  ggplot(aes(x = menarche, y = bwt)) +
  geom_boxplot()

baby_df %>% 
  mutate(
    parity = as.factor(parity),
    parity = fct_reorder(parity, bwt)
  ) %>% 
  ggplot(aes(x = parity, y = bwt)) +
  geom_boxplot()

baby_df %>% 
  ggplot(aes(x = ppbmi, y = bwt)) +
  geom_point()

baby_df %>% 
  ggplot(aes(x = smoken, y = bwt)) +
  geom_point()

baby_df %>% 
  mutate(
    smoken = as.factor(smoken),
    smoken = fct_reorder(smoken, bwt)
  ) %>% 
  ggplot(aes(x = smoken, y = bwt)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

baby_df %>% 
  ggplot(aes(x = wtgain, y = bwt)) +
  geom_point()  
```

Next, I will fit univariate linear models to assess the p values of variables for consideration for inclusion into my model, at a level of statistical significance of p < 0.05.  A priori based on my exploratory ggplots and biological theory, I will definitely select babysex, mrace, momwt, bhead, blength, gaweeks.
```{r, explore the data with univariate linear regression models}
#First, univariate regression of my a priori selected variables
lm(bwt ~ babysex, data = baby_df) %>% broom::tidy()
#p = 0.0000000108
lm(bwt ~ mrace, data = baby_df) %>% broom::tidy()
#with white as reference, black maternal race (p = 6.25e-90) and puerto rican maternal race (-6.39 1.86e-10) are statistically significant
lm(bwt ~ momwt, data = baby_df) %>% broom::tidy()
#p = 1.22e-83
lm(bwt ~ bhead, data = baby_df) %>% broom::tidy()
#p = 0, collinear variables?
lm(bwt ~ blength, data = baby_df) %>% broom::tidy()
#p = 0, collinear?
lm(bwt ~ gaweeks, data = baby_df) %>% broom::tidy()
#p = 9.69e-178

#next, the other variables
lm(bwt ~ fincome, data = baby_df) %>% broom::tidy()
#p = 1.26e-24
lm(bwt ~ frace, data = baby_df) %>% broom::tidy()
#with white as reference, black paternal race and puerto rican race are statistically significant (6.25e-90 and 1.86e-10 respectively)
lm(bwt ~ malform, data = baby_df) %>% broom::tidy()
#p = 0.930
lm(bwt ~ menarche, data = baby_df) %>% broom::tidy()
#p = 0.108
lm(bwt ~ parity, data = baby_df) %>% broom::tidy()
#p = 0.581
lm(bwt ~ ppbmi, data = baby_df) %>% broom::tidy()
#p = 5.56e-10
lm(bwt ~ ppwt, data = baby_df) %>% broom::tidy()
#p = 5.69e-34
lm(bwt ~ smoken, data = baby_df) %>% broom::tidy()
#p = 0.000000607
lm(bwt ~ wtgain, data = baby_df) %>% broom::tidy()
#p = 1.73e-61
```

Based on a univariate analyses, the following predictors are statistically significant at the p < 0.05 level: babysex, mrace, momwt, gaweeks, fincome, frace, ppbmi, ppwt, smoken, and wtgain.  Bhead and blength have p values equal to zero - I wonder if these are collinear variables (since they all kind of measure the same thing).  I will include these anyway because, why not?

So my final model will consist of the following variables: babysex, mrace, momwt, gaweeks, fincome, frace, ppbmi, ppwt, smoken, wtgain, bhead and blength.  I will not assess for confounding or interaction at this time, and if I have time, I will come back and assess for these.  In particular, babysex and mrace may show important interactions for further exploration.  For now, this seems to be "reasonable" model for me to move forward in the homework problem to perform cross-validation.

```{r}
lm_3 = lm(bwt ~ gaweeks + bhead + blength + momwt + babysex + mrace + frace + fincome + ppbmi + ppwt + smoken + wtgain, data = baby_df) 

lm_3 %>%
  broom::tidy()
```

Diagnostics on my model...
```{r}
modelr::add_residuals(baby_df, lm_3)

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = gaweeks, y = resid)) +
  geom_violin()
#the distribution of the residuals is mostly around 0, but there are some outliers and skewness towards +2

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = bhead, y = resid)) +
  geom_violin()
#the distribution of the residuals is mostly around 0, but there are some outliers and some skewness towards +2

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = blength, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = momwt, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = babysex, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = mrace, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = frace, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = fincome, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = ppbmi, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = ppwt, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = smoken, y = resid)) +
  geom_violin()

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = wtgain, y = resid)) +
  geom_violin()

#in general, these plots all show some skewness

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = gaweeks, y = resid)) +
  geom_point() +
  facet_wrap(. ~ mrace)

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = gaweeks, y = resid)) +
  geom_violin() +
  facet_wrap(. ~ mrace)

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = bhead, y = resid)) +
  geom_violin() +
  facet_wrap(. ~ mrace)

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = momwt, y = resid)) +
  geom_violin() +
  facet_wrap(. ~ mrace)

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = gaweeks, y = resid)) +
  geom_point() +
  facet_wrap(. ~ babysex)

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = bhead, y = resid)) +
  geom_point() +
  facet_wrap(. ~ babysex)

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = gaweeks, y = resid)) +
  geom_point() +
  facet_wrap(. ~ frace)

modelr::add_residuals(baby_df, lm_3) %>% 
  ggplot(aes(x = gaweeks, y = resid)) +
  geom_violin() +
  facet_wrap(. ~ frace)

#use add_predictions

modelr::add_predictions(baby_df, lm_3)

#modelr::add_predictions(baby_df, lm_3) %>% View()

#3 plots using add_predictions:

baby_df %>% 
  modelr::add_residuals(lm_3) %>% 
  ggplot(aes(x = gaweeks, y = resid)) +
  geom_violin()

baby_df %>% 
  modelr::add_residuals(lm_3) %>% 
  ggplot(aes(x = bhead, y = resid)) +
  geom_violin() +
  facet_wrap(. ~ babysex)

baby_df %>% 
  modelr::add_residuals(lm_3) %>% 
  ggplot(aes(x = gaweeks, y = resid)) +
  geom_violin() +
  facet_wrap(. ~ mrace)

#in general, some skewness in positive direction, less so in puerto rican race
```
In general, the distribution of residuals shows some skewness towards higher values, likely reflecting outliers in the data.  The pattern and trend of the residuals seem to be clustered around a central blok and seems overall linear.  There does not appear to be a non-linear or parabolic pattern.


Next, I will first fit the two specified models in the homework and perform cross-validation just for these two models, to make sure I can do it correctly.
```{r}
lm_1 = lm(bwt ~ blength + gaweeks, data = baby_df) %>% broom::tidy()
lm_2 = lm(bwt ~ bhead * blength * babysex, data = baby_df) %>% broom::tidy()

cv_df = crossv_mc(baby_df, 100)

cv_df %>% pull(train) %>% .[[1]] %>% as_tibble()
cv_df %>% pull(test) %>% .[[1]] %>% as_tibble()

cv_df =
  cv_df %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

#get RMSEs for my models
cv_df =
  cv_df %>% 
  mutate(
    lm_1 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    lm_2 = map(.x = train, ~lm(bwt ~ bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmse_lm_1 = map2_dbl(.x = lm_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_lm_2 = map2_dbl(.x = lm_2, .y = test, ~rmse(model = .x, data = .y))
  )

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()
#Based on this distribution of RMSEs, lm_2 is doing better.

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  group_by(model) %>% 
  summarize(avg_rmse = mean(rmse)) %>% 
  knitr::kable()
```

Now, I perform cross-validation for all 3 models, including the model that I fit.
```{r}
#get RMSEs for all 3 models
cv_df =
  cv_df %>% 
  mutate(
    lm_1 = map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    lm_2 = map(.x = train, ~lm(bwt ~ bhead * blength * babysex, data = .x)),
    lm_3 = map(.x = train, ~lm(bwt ~ gaweeks + bhead + blength + momwt + babysex + mrace + frace + fincome + ppbmi + ppwt +                smoken + wtgain, data = .x))
  ) %>% 
  mutate(
    rmse_lm_1 = map2_dbl(.x = lm_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_lm_2 = map2_dbl(.x = lm_2, .y = test, ~rmse(model = .x, data = .y)),
    rmse_lm_3 = map2_dbl(.x = lm_3, .y = test, ~rmse(model = .x, data = .y))
  )

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()
#Based on this distribution of RMSEs, lm_3 seems to have lower residuals, and doing better.

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  group_by(model) %>% 
  summarize(avg_rmse = mean(rmse)) %>% 
  knitr::kable()
```

Overall, the average RMSE is lowest for model #3 compared to the other models, suggesting it provides the best prediction.  However, the model contains a lot of predictors and is less parsimonious than the other models.  Some of the predictors could confound each other.  There may be interactions that I have not explored, particularly by gender and race.  If I were to spend more time on model-building, I could explore interactions and confounders of the association between bwt and gaweeks, because gaweeks is biologically, the length of pregnancy is one of the most important predictors of birth weight.  In addition, statistically, gaweeks seemed to return the smallest p value on univariate regression.

```{r, include = FALSE}
# #try the "by hand" method first - could not get this to work, will ask TAs
# train_df = sample_n(baby_df, size = 3474) 
# test_df = anti_join(baby_df, train_df, by = "id")
# 
# #confirm that the train_df and test_df are not the same observations
# train_df %>% arrange(id)
# test_df %>% arrange(id)
# 
# lm_1 = lm(bwt ~ blength + gaweeks, data = train_df) %>% broom::tidy()
# lm_2 = lm(bwt ~ bhead * blength * babysex, data = train_df) %>% broom::tidy()
# 
# rmse(lm_1, test_df)
# rmse(lm_2, test_df)
```

# Problem 3
```{r, echo = FALSE}
#These are my notes from synchronous class for guidance - please ignore, thank you.

# Central Park Weather dataset
# Try to use the bootstrap to obtain distributions for parameters that you are interested in - will eventually calculate a confidence interval
# Process:
# (1) download dataset - make sure that that works
# (2) fit model to that dataset
# (3) make sure to be able to calculate R^2 (use "broom::glance()")and the specified log computation
# 
# fit a linear model of max temp vs min temp -- two things interested in (1) R2 value - the proportion of outcome variation explained by the predictor and (2) log(estimated intercept * estimated slope) - get broom tidy, get your estimated coefficients, get them next to each other, them multiply and do log.  start with one model first to get the process for one, then how do you do it for multiple with bootstrap samples).  Then, once you're done and by the end, you making plots and/or group by, making confidence intervals for R^2 and log computation.
```

First, I download the data and fit the specified model.

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

lm_weather = lm(tmax ~ tmin, data = weather_df)

lm_weather %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_point() +
  geom_smooth(method = "lm")
#appears pretty linear
```

Next, bootstrapping.  I will write the bootstrap function first.

```{r}
boot_sample = function(df) {
  
  sample_frac(df, replace = TRUE) %>% 

    arrange(tmin)

}
```

Now I check that this works

```{r}
boot_sample(weather_df) %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_point(alpha = .3) +
  geom_smooth(method = "lm")

boot_sample(weather_df) %>% 
  lm(tmax ~ tmin, data = .) %>% 
  broom::tidy()
```

Draw many bootstrap samples, first setting 100 samples to save time and see if my code works.  In my final code, I will increase to 5000 samples.

```{r}
boot_straps =
  tibble(
    strap_number = 1:100,
    strap_sample = rerun(100, boot_sample(weather_df))
  )

boot_straps %>% pull(strap_sample)
boot_straps %>% pull(strap_sample) %>% .[[1]]
boot_straps %>% pull(strap_sample) %>% .[[21]]
boot_straps %>% pull(strap_sample) %>% .[[97]]


```

Generate models for strap_sample tibbles

```{r}
boot_results =
  boot_straps %>% 
  mutate(
    models = map(.x = strap_sample, ~lm(tmax ~ tmin, data = .x)),
    r_squared = map(models, broom::glance),
    results = map(models, broom::tidy)
  ) %>% 
  unnest(r_squared) %>%
  select(strap_number, models, r.squared, results) %>% 
  mutate(
    r_squared = r.squared,
    r_sq_ci_lower = quantile(r.squared, 0.025),
    r_sq_ci_upper = quantile(r.squared, 0.975)
  ) %>% 
  unnest(results) %>% 
  select(strap_number, r_squared, r_sq_ci_lower, r_sq_ci_upper, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  mutate(
    log_computation = log(`(Intercept)` * tmin),
    log_comp_ci_lower = quantile(log_computation, 0.025),
    log_comp_ci_upper = quantile(log_computation, 0.975)
  ) %>% 
  select(-`(Intercept)`, -tmin)

boot_results %>% 
  ggplot(aes(x = r_squared)) +
  geom_histogram()

boot_results %>% 
  ggplot(aes(x = r_squared)) +
  geom_density()

boot_results %>% 
  ggplot(aes(x = log_computation)) +
  geom_histogram()

boot_results %>% 
  ggplot(aes(x = log_computation)) +
  geom_density()

```

The distribution of r_squared and log(Bo * B1) appears normally distributed for 100 bootstrap samples.  I will now repeat the code for 5000 bootstrap samples.

```{r}
boot_straps =
  tibble(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

boot_results =
  boot_straps %>% 
  mutate(
    models = map(.x = strap_sample, ~lm(tmax ~ tmin, data = .x)),
    r_squared = map(models, broom::glance),
    results = map(models, broom::tidy)
  ) %>% 
  unnest(r_squared) %>%
  select(strap_number, models, r.squared, results) %>% 
  mutate(
    r_squared = r.squared,
    r_sq_ci_lower = quantile(r.squared, 0.025),
    r_sq_ci_upper = quantile(r.squared, 0.975)
  ) %>% 
  unnest(results) %>% 
  select(strap_number, r_squared, r_sq_ci_lower, r_sq_ci_upper, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  mutate(
    log_computation = log(`(Intercept)` * tmin),
    log_comp_ci_lower = quantile(log_computation, 0.025),
    log_comp_ci_upper = quantile(log_computation, 0.975)
  ) %>% 
  select(-`(Intercept)`, -tmin)

boot_results %>% 
  ggplot(aes(x = r_squared)) +
  geom_histogram()

boot_results %>% 
  ggplot(aes(x = r_squared)) +
  geom_density()

boot_results %>% 
  ggplot(aes(x = log_computation)) +
  geom_histogram()

boot_results %>% 
  ggplot(aes(x = log_computation)) +
  geom_density()

```

The distribution of r_squared appears normally distributed, but with a leftward skew.
The distribution of log(B0 * B1) also appears to be normally distributed with a slight leftward skew.
